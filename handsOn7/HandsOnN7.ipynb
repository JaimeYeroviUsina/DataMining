{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ade8ae06-7474-42e1-9e41-88f2ff195712",
   "metadata": {},
   "source": [
    "7 Linear Regression with TensorFlow using the California Housing Dataset\n",
    "\n",
    "The goal of this exercise is to implement a linear regression model using TensorFlow to predict house prices based on the California Housing Dataset. The dataset contains various features such as average income, housing average age, and more. Your task is to build a linear regression model and evaluate its performance.\n",
    "\n",
    "Import the required libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b8e69e0-c6b1-4387-b9e9-ee3ed7d0916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as v1\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ba2545-63cd-41cd-a6ef-2810af9fc243",
   "metadata": {},
   "source": [
    "Load the California Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37f01e43-e4e9-4ff2-ad10-f0b0f6474304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "...       ...       ...       ...        ...         ...       ...       ...   \n",
      "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
      "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
      "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
      "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
      "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
      "\n",
      "       Longitude  \n",
      "0        -122.23  \n",
      "1        -122.22  \n",
      "2        -122.24  \n",
      "3        -122.25  \n",
      "4        -122.25  \n",
      "...          ...  \n",
      "20635    -121.09  \n",
      "20636    -121.21  \n",
      "20637    -121.22  \n",
      "20638    -121.32  \n",
      "20639    -121.24  \n",
      "\n",
      "[20640 rows x 8 columns]\n",
      "0        4.526\n",
      "1        3.585\n",
      "2        3.521\n",
      "3        3.413\n",
      "4        3.422\n",
      "         ...  \n",
      "20635    0.781\n",
      "20636    0.771\n",
      "20637    0.923\n",
      "20638    0.847\n",
      "20639    0.894\n",
      "Length: 20640, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "raw = fetch_california_housing()\n",
    "X = pd.DataFrame(data=raw['data'], columns=raw['feature_names'])\n",
    "y = pd.Series(raw['target'])\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245e77b8-2aca-4c0a-83c8-1a66b02f1d87",
   "metadata": {},
   "source": [
    "Preprocess the data:\n",
    "\n",
    "Normalize the features using the mean and standard deviation.\n",
    "Split the dataset into training and testing sets (e.g., 80% for training, 20% for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ad1d557-bd65-4221-b8d8-1e37eb8cb181",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20cb6e4-d8b8-4a96-9b00-d5f3ab891a40",
   "metadata": {},
   "source": [
    "Define the TensorFlow graph:\n",
    "\n",
    "Create placeholders for the input features (X) and target variable (y).\n",
    "Create variables for the model's weights (W) and bias (b).\n",
    "Define the linear regression model using the equation: y_pred = X * W + b.\n",
    "Define the loss function as the mean squared error between the predicted values and the true values.\n",
    "Choose an optimizer (e.g., Gradient Descent) to minimize the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fa481b9-b11e-44cc-b5dc-63bba2f23857",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tf.placeholder() is not compatible with eager execution.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_placeholder \u001b[38;5;241m=\u001b[39m \u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplaceholder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m y_placeholder \u001b[38;5;241m=\u001b[39m v1\u001b[38;5;241m.\u001b[39mplaceholder(tf\u001b[38;5;241m.\u001b[39mfloat32, shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[0;32m      4\u001b[0m w \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(tf\u001b[38;5;241m.\u001b[39mrandom_normal_initializer[X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:3169\u001b[0m, in \u001b[0;36mplaceholder\u001b[1;34m(dtype, shape, name)\u001b[0m\n\u001b[0;32m   3122\u001b[0m \u001b[38;5;124;03m\"\"\"Inserts a placeholder for a tensor that will be always fed.\u001b[39;00m\n\u001b[0;32m   3123\u001b[0m \n\u001b[0;32m   3124\u001b[0m \u001b[38;5;124;03m**Important**: This tensor will produce an error if evaluated. Its value must\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3166\u001b[0m \u001b[38;5;124;03m@end_compatibility\u001b[39;00m\n\u001b[0;32m   3167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m-> 3169\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.placeholder() is not compatible with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3170\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager execution.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gen_array_ops\u001b[38;5;241m.\u001b[39mplaceholder(dtype\u001b[38;5;241m=\u001b[39mdtype, shape\u001b[38;5;241m=\u001b[39mshape, name\u001b[38;5;241m=\u001b[39mname)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: tf.placeholder() is not compatible with eager execution."
     ]
    }
   ],
   "source": [
    "X_placeholder = v1.placeholder(tf.float32, shape=[None, X_train.shape[1]])\n",
    "y_placeholder = v1.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "w = tf.Variable(tf.random_normal_initializer[X_train.shape[1],1])\n",
    "b = tf.Variable(tf.random_normal_initializer(1))\n",
    "\n",
    "y_pred = tf.matmul(X_placeholder, w)+b\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y_pred - y_placeholder))\n",
    "\n",
    "optimizer = tf.optimizers.SGD()\n",
    "\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad8f83a1-652f-47f7-8f0a-66fe81125c05",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m      2\u001b[0m num_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSession\u001b[49m() \u001b[38;5;28;01mas\u001b[39;00m tfsession:\n\u001b[0;32m      5\u001b[0m   tfsession\u001b[38;5;241m.\u001b[39mrun(tf\u001b[38;5;241m.\u001b[39mglobal_variables_initializer())\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epoch):\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epoch = 5\n",
    "\n",
    "with tf.Session() as tfsession:\n",
    "  tfsession.run(tf.global_variables_initializer())\n",
    "\n",
    "  for epoch in range(num_epoch):\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "      batch_X = X_train[i:i+batch_size]\n",
    "      batch_y = y_train[i:i+batch_size]\n",
    "\n",
    "      tfsession.run(train_op,feed_dict={X_placeholder: batch_X, y_placeholder: batch_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc85d880-bb63-487e-8fa7-f2c48679375c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
